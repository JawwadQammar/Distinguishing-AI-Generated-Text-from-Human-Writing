{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1iDvowitWOVA"
      },
      "source": [
        "# Baseline Model\n",
        "\n",
        "## Table of Contents\n",
        "1. [Model Choice](#model-choice)\n",
        "2. [Feature Selection](#feature-selection)\n",
        "3. [Implementation](#implementation)\n",
        "4. [Evaluation](#evaluation)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qzBRmUOFWOVE"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd  # Import pandas for data manipulation and analysis.\n",
        "import matplotlib.pyplot as plt  # Import matplotlib for plotting graphs and visualizations.\n",
        "from wordcloud import WordCloud  # Import WordCloud for creating word cloud visualizations.\n",
        "from sklearn.feature_extraction.text import CountVectorizer  # Import CountVectorizer for converting text to numerical data.\n",
        "from sklearn.utils import shuffle  # Import shuffle to randomize the order of data.\n",
        "from scipy.sparse import hstack  # Import hstack to combine sparse matrices.\n",
        "from sklearn.model_selection import train_test_split, cross_val_predict, cross_val_score  # Import methods for model validation and splitting data.\n",
        "from sklearn.linear_model import LogisticRegression  # Import LogisticRegression for classification tasks.\n",
        "from sklearn.ensemble import RandomForestClassifier  # Import RandomForestClassifier for classification using an ensemble of decision trees.\n",
        "from sklearn.metrics import accuracy_score, classification_report  # Import metrics to evaluate model performance.\n",
        "from sklearn.svm import SVC  # Import Support Vector Classifier for classification tasks.\n",
        "from sklearn.neighbors import KNeighborsClassifier  # Import KNeighborsClassifier for classification using K-nearest neighbors.\n",
        "from sklearn.naive_bayes import MultinomialNB  # Import MultinomialNB for Naive Bayes classification.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lN7yGoimWOVG"
      },
      "source": [
        "## Model Choice\n",
        "\n",
        "[Explain why you've chosen a particular model as the baseline. This could be a simple statistical model or a basic machine learning model. Justify your choice.]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgAngEXKWOVH"
      },
      "source": [
        "## Feature Selection\n",
        "\n",
        "[Indicate which features from the dataset you will be using for the baseline model, and justify your selection.]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "szyUS1_XWOVI"
      },
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "# Replace 'your_dataset.csv' with the path to your actual dataset\n",
        "df = pd.read_csv('/content/Combined-Text-Dataset.csv')\n",
        "\n",
        "# Feature selection\n",
        "# Example: Selecting only two features for a simple baseline model\n",
        "# X = df[['feature1', 'feature2']]\n",
        "# y = df['target_variable']\n",
        "\n",
        "# Splitting the dataset\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "#We are initializing separate `CountVectorizer` objects for the `abstract`, `title`, and `keyword` columns. These vectorizers will convert the text data into numerical features suitable for machine learning models.\n",
        "vectorizer_abstract = CountVectorizer()  # Initialize a CountVectorizer for the 'abstract' column to convert text data into a matrix of token counts.\n",
        "vectorizer_title = CountVectorizer()  # Initialize a CountVectorizer for the 'title' column for the same purpose.\n",
        "vectorizer_keyword = CountVectorizer()  # Initialize a CountVectorizer for the 'keyword' column to convert keyword text data into numerical features.\n",
        "\n",
        "\n",
        "## Transforming Text Data into Numerical Features\n",
        "X_abstract = vectorizer_abstract.fit_transform(df['abstract'])  # Fit the CountVectorizer on the 'abstract' column and transform the text data into a numerical feature matrix.\n",
        "X_title = vectorizer_title.fit_transform(df['title'])  # Fit the CountVectorizer on the 'title' column and transform the text data into a numerical feature matrix.\n",
        "X_keyword = vectorizer_keyword.fit_transform(df['keyword'])  # Fit the CountVectorizer on the 'keyword' column and transform the text data into a numerical feature matrix.\n",
        "\n",
        "# Combine the feature matrices from 'abstract', 'title', and 'keyword' into a single sparse matrix using horizontal stacking.\n",
        "X = hstack([X_abstract, X_title, X_keyword])\n",
        "\n",
        "# Define the target variable 'y' as the 'is_human' column, which contains labels for human-written (1) and AI-generated (0) text.\n",
        "y = df['is_human']\n",
        "\n",
        "# Splitting the Data into Training and Testing Sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "# Split the data into training and testing sets.\n",
        "# 'test_size=0.2' means 20% of the data will be used for testing, while 80% will be used for training.\n",
        "# 'random_state=42' ensures reproducibility by fixing the randomness in the split.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PZ_nb76WOVI"
      },
      "source": [
        "## Implementation\n",
        "\n",
        "[Implement your baseline model here.]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XlKDMnufWOVJ"
      },
      "outputs": [],
      "source": [
        "# Initialize and train the baseline model\n",
        "# Example for a classification problem using Logistic Regression\n",
        "# model = LogisticRegression()\n",
        "# model.fit(X_train, y_train)\n",
        "\n",
        "# Your implementation code here\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression\n",
        "# training\n",
        "results = {}  # Initialize an empty dictionary to store the results of different models.\n",
        "model = LogisticRegression()  # Create an instance of the LogisticRegression model.\n",
        "model.fit(X_train, y_train)  # Train the logistic regression model using the training data (X_train and y_train).\n",
        "\n",
        "# Predictions\n",
        "y_pred = model.predict(X_test)  # Use the trained logistic regression model to predict labels for the test data (X_test).\n"
      ],
      "metadata": {
        "id": "t4wI-DtcmsSw"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest\n",
        "# training\n",
        "rf_model = RandomForestClassifier()  # Initialize the Random Forest classifier.\n",
        "rf_model.fit(X_train, y_train)  # Train the Random Forest model using the training data.\n",
        "\n",
        "# Predictions\n",
        "y_pred_rf = rf_model.predict(X_test)  # Predict the labels for the test data using the trained Random Forest model.\n"
      ],
      "metadata": {
        "id": "q3Rw0ZmvpnTW"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Support Vector Machine (SVM)\n",
        "# training\n",
        "svm_model = SVC()  # Initialize the Support Vector Machine (SVM) classifier.\n",
        "svm_model.fit(X_train, y_train)  # Train the SVM model using the training data.\n",
        "\n",
        "# Predictions\n",
        "y_pred_svm = svm_model.predict(X_test)  # Predict the labels for the test data using the trained SVM model.\n"
      ],
      "metadata": {
        "id": "WHQi-jAIra39"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# K-Nearest Neighbors (KNN)\n",
        "# training\n",
        "knn_model = KNeighborsClassifier()  # Initialize the K-Nearest Neighbors (KNN) classifier.\n",
        "knn_model.fit(X_train, y_train)  # Train the KNN model using the training data.\n",
        "\n",
        "# Predictions\n",
        "y_pred_knn = knn_model.predict(X_test)  # Predict the labels for the test data using the trained KNN model.\n"
      ],
      "metadata": {
        "id": "cmJ4YotRsssn"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Naive Bayes\n",
        "# training\n",
        "nb_model = MultinomialNB()  # Initialize the Naive Bayes classifier.\n",
        "nb_model.fit(X_train, y_train)  # Train the Naive Bayes model using the training data.\n",
        "\n",
        "# Predictions\n",
        "y_pred_nb = nb_model.predict(X_test)  # Predict the labels for the test data using the trained Naive Bayes model.\n"
      ],
      "metadata": {
        "id": "xEGa6RDbttD-"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ln7O47DVWOVJ"
      },
      "source": [
        "## Evaluation\n",
        "\n",
        "[Clearly state what metrics you will use to evaluate the model's performance. These metrics will serve as a starting point for evaluating more complex models later on.]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "o1JzAwn9WOVK"
      },
      "outputs": [],
      "source": [
        "# Evaluate the baseline model\n",
        "# Example for a classification problem\n",
        "# y_pred = model.predict(X_test)\n",
        "# accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# For a regression problem, you might use:\n",
        "# mse = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "# Your evaluation code here\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression\n",
        "# evaluation\n",
        "accuracy = accuracy_score(y_test, y_pred)  # Calculate the accuracy of the model by comparing the predicted labels (y_pred) to the actual labels (y_test).\n",
        "\n",
        "# results\n",
        "print(f\"Logistic_Regression Accuracy: {accuracy}\")  # Print the accuracy of the model, formatted for easy readability.\n",
        "results['Logistic_Regression'] = accuracy  # Store the accuracy of the logistic regression model in the 'results' dictionary under the key 'Logistic_Regression'.\n",
        "report = classification_report(y_test, y_pred)  # Generate a classification report that includes precision, recall, F1-score, and support for each class.\n",
        "print(f\"Classification Report:\\n{report}\")  # Print the classification report to evaluate the model's performance.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4130d11f-c7a5-49d9-bbea-70dec764a85a",
        "id": "i0R7VBRCwV_b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic_Regression Accuracy: 0.9818122767132186\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.98      3050\n",
            "           1       0.99      0.98      0.98      3108\n",
            "\n",
            "    accuracy                           0.98      6158\n",
            "   macro avg       0.98      0.98      0.98      6158\n",
            "weighted avg       0.98      0.98      0.98      6158\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest\n",
        "# evaluation\n",
        "accuracy = accuracy_score(y_test, y_pred_rf)  # Calculate the accuracy of the model by comparing the predicted labels (y_pred) to the actual labels (y_test).\n",
        "\n",
        "# results\n",
        "print(f\"Random Forest Accuracy: {accuracy}\")  # Print the accuracy of the model, formatted for easy readability.\n",
        "results['Random Forest'] = accuracy  # Store the accuracy of the Random Forest model in the 'results' dictionary under the key 'Random Forest'.\n",
        "report = classification_report(y_test, y_pred_rf)  # Generate a classification report for the Random Forest model.\n",
        "print(f\"Classification Report:\\n{report}\")  # Print the classification report to evaluate the model's performance.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4855b387-edce-4632-9d7d-7505dcb550ef",
        "id": "xNhmvNMbwdc2"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Accuracy: 0.9699577784995128\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.98      0.97      3050\n",
            "           1       0.98      0.96      0.97      3108\n",
            "\n",
            "    accuracy                           0.97      6158\n",
            "   macro avg       0.97      0.97      0.97      6158\n",
            "weighted avg       0.97      0.97      0.97      6158\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Support Vector Machine (SVM)\n",
        "# evaluation\n",
        "accuracy = accuracy_score(y_test, y_pred_svm)  # Calculate the accuracy of the model by comparing the predicted labels (y_pred) to the actual labels (y_test).\n",
        "\n",
        "# results\n",
        "print(f\"SVM Accuracy: {accuracy}\")  # Print the accuracy of the model, formatted for easy readability.\n",
        "results['SVM'] = accuracy  # Store the accuracy of the SVM model in the 'results' dictionary under the key 'SVM'.\n",
        "report = classification_report(y_test, y_pred_svm)  # Generate a classification report for the SVM model.\n",
        "print(f\"Classification Report:\\n{report}\")  # Print the classification report to evaluate the model's performance.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb1ab066-4dc6-427f-db93-332f6d1485f4",
        "id": "G6Pu22W8wjMG"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Accuracy: 0.9787268593699253\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98      3050\n",
            "           1       0.98      0.98      0.98      3108\n",
            "\n",
            "    accuracy                           0.98      6158\n",
            "   macro avg       0.98      0.98      0.98      6158\n",
            "weighted avg       0.98      0.98      0.98      6158\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# K-Nearest Neighbors (KNN)\n",
        "# evaluation\n",
        "accuracy = accuracy_score(y_test, y_pred_knn)  # Calculate the accuracy of the model by comparing the predicted labels (y_pred) to the actual labels (y_test).\n",
        "\n",
        "# results\n",
        "print(f\"KNN Accuracy: {accuracy}\")  # Print the accuracy of the model, formatted for easy readability.\n",
        "results['KNN'] = accuracy  # Store the accuracy of the KNN model in the 'results' dictionary under the key 'KNN'.\n",
        "report = classification_report(y_test, y_pred_knn)  # Generate a classification report for the KNN model.\n",
        "print(f\"Classification Report:\\n{report}\")  # Print the classification report to evaluate the model's performance.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3775f2f8-8c77-4daf-ad25-213f5e53b4bd",
        "id": "1pq62l5hwq6W"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN Accuracy: 0.6053913608314387\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.45      0.53      3050\n",
            "           1       0.58      0.75      0.66      3108\n",
            "\n",
            "    accuracy                           0.61      6158\n",
            "   macro avg       0.61      0.60      0.60      6158\n",
            "weighted avg       0.61      0.61      0.60      6158\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Naive Bayes\n",
        "# evaluation\n",
        "accuracy = accuracy_score(y_test, y_pred_nb)  # Calculate the accuracy of the model by comparing the predicted labels (y_pred) to the actual labels (y_test).\n",
        "\n",
        "# results\n",
        "print(f\"Naive Bayes Accuracy: {accuracy}\")  # Print the accuracy of the model, formatted for easy readability.\n",
        "results['Naive Bayes'] = accuracy  # Store the accuracy of the Naive Bayes model in the 'results' dictionary under the key 'Naive Bayes'.\n",
        "report = classification_report(y_test, y_pred_nb)  # Generate a classification report for the Naive Bayes model.\n",
        "print(f\"Classification Report:\\n{report}\")  # Print the classification report to evaluate the model's performance.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a614a2c-2f9f-4d28-bf2e-448a6c6f9945",
        "id": "qGr24Kg5wx07"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Accuracy: 0.936342968496265\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.95      0.94      3050\n",
            "           1       0.95      0.92      0.94      3108\n",
            "\n",
            "    accuracy                           0.94      6158\n",
            "   macro avg       0.94      0.94      0.94      6158\n",
            "weighted avg       0.94      0.94      0.94      6158\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results  # Display the dictionary containing accuracy scores for all models evaluated so far.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwoOHGAtxEr6",
        "outputId": "27484439-e7b9-446d-9d21-9c4e1d2c82f8"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Logistic_Regression': 0.9818122767132186,\n",
              " 'Random Forest': 0.9699577784995128,\n",
              " 'SVM': 0.9787268593699253,\n",
              " 'KNN': 0.6053913608314387,\n",
              " 'Naive Bayes': 0.936342968496265}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}